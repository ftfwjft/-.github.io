## 势能面传递学习在掺杂和合金原子建模中的应用



#### Abstract

本文提出了一种迁移学习(TL)方法来生成神经网络(NN)数据库来模拟掺杂和合金。通过利用源系统中已有的有价值的势能面(PES)信息以及源系统和目标系统之间的相似性，提出的TL成功地将计算成本降低了几个数量级，同时保持了ab-initio级的高精度。我们证明它一般适用于p型、n型和合金原子取代。



#### INTRODUCTION

为了模拟这些重要的原子效应和新合金的未知性质，密度泛函理论(DFT)和基于DFT的ab-initio技术计算机辅助设计(TCAD)工具已被广泛应用于学术界和工业界。DFT和ab-initio  TCAD最重要的任务之一是计算势能面及其导数——原子力，这两者都是进行各种模拟(如分子动力学、蒙特卡罗、肘击弹性带等)不可缺少的

DFT和ab-initio  TCAD可以从第一性原理(即不需要实验校准参数作为输入)计算各种材料，因此它们是强大的设计工具。

研究发现，基于监督学习(SL)的人工神经网络(NN)比DFT快几个数量级，保持了DFT级的高精度[12]。尽管NN推理速度快，但其SL训练需要大量的推理量。由于材料特异性，针对一种材料训练的神经网络不能用于建模另一种材料。在这篇文章中，我们提出了一种高效的迁移学习(TL)方法，与SL相比，它可以减少数量级的计算成本。第二节讨论了传统的TL。第三节和第四节介绍了提出的TL。第五节展示了结果。第六节是结论。



#### 监督学习

如图1所示，SL使用原子坐标R和DFT能量E的MS样本来训练MLP  (multilayer perceptron) NN。为了将高维(HD) PES应用于SL训练，R被转换为特征D(一个nd维向量)，以考虑对称性

![image-20220216182431397](https://gitee.com/ftfwjft/images/raw/master/image/cloud/image-20220216182431397.png)

**![image-20220216182535892](https://gitee.com/ftfwjft/images/raw/master/image/cloud/image-20220216182535892.png)**

自这一重要方法[发表以来，HD  PES的SL已被广泛应用，因为它可以比DFT快一个数量级的计算PES。不幸的是，在半导体掺杂和合金模拟领域，两种固有的缺陷阻碍了其应用:

1. 首先，每个DFT样本只对训练数据集贡献一个数据点E。因此，为了生成足够的数据点，需要对一种材料进行大量的DFT样本MS的训练
2. 其次，经过训练的SiNN(比如“Si64”，一个有64个原子的超级单体)，如果只替换一个原子来解释合金/掺杂效应,这个SiNN将完全无用。



#### ld pes的迁移学习

由于高清PES极其复杂,寻求灵感来弥补这些缺陷(第二部分),我们采取简单的LD PES H2O n d硫化氢(O年代)代替。我们使用1000  DFT的水样本训练一个延时两个8-neuron隐藏层.

![image-20220216182825938](https://gitee.com/ftfwjft/images/raw/master/image/cloud/image-20220216182825938.png)

为了弥补这些差异，我们尝试在特征域和MLP模型上进行了两次转移。在域转移中，我们对H2S的特征进行平移操作(图2(c)中的蓝色圆)，使H2S的特征样本均值与H2O的特征样本均值重叠。

我们在现有的两层隐藏层的基础上，增加了一个4神经元的隐藏层。在转移的MLP的后续训练中，我们只更新与添加层相关的权值和偏差，其他参数与原H2O  MLP中保持一致。基于这两种转移，我们发现，仅使用25个H2S  DFT样本进行训练后，转移的MLP可以很好地预测H2S的PES(图2(b)中的蓝色圈)。值得注意的是，通过利用H2O M L P中已经存在的丰富的H2O  PES信息(图2(a))以及H2O PES与H2S PES之间的相似性，25远小于1000



#### hd pes的迁移学习

这种聚醚砜的相似性(第三节)广泛存在于合金和掺杂剂的HD聚醚砜中，本文通过结合SL和TL来降低Nall。当SL训练一个NN模型时，TL在一个新问题上重用一个预先训练的模型。我们没有使用传统的SL，而是采用了最近提出的SL，这样每个DFT样本不仅向训练数据集贡献一个能量，还向训练集贡献了一个原子力Fi。

如果将源系统中的一个原子替换为模型合金或掺杂(记为“目标”)，则使用域转移和模型转移来使用源神经网络生成目标神经网络。在不失一般性的前提下，源神经网络和目标神经网络都有1个输入层Linp  (Nd neurons)， 5个隐藏层Li (i =  1,2，…，5)，和1个输出层Lout。L1、L2、L3、L4、L5分别有Nd、200、100、50、50个神经元。Linp中的任意一个神经元只与L1中的一个神经元(总Nd权重)连接，且没有激活功能;Li  to Li+1 (i = 1, 2, 3, 4)， L5 to  Lout为全连接，与普通前馈MLP相同。L1被设计用来进行域转移，因为从Linp到L1的每一个连接都会移动和缩放一个特征;L2到L5执行模型转移。

![image-20220216183158439](https://gitee.com/ftfwjft/images/raw/master/image/cloud/image-20220216183158439.png)

![image-20220216183236332](https://gitee.com/ftfwjft/images/raw/master/image/cloud/image-20220216183236332.png)

#### RESULTS

使用TL1(图3),神经网络推理的准确性显著增强SL相比,基于相同数量的训练样本(图4)。TL的准确性可以进一步提高通过改变TL1  TL2,它使用多个源系统的共享权重(绿色神经元在图3)SL r e第一次一起训练,然后在后面的TL中重复使用。这里，能量eE和原子力eF的推断误差

![image-20220216183304542](https://gitee.com/ftfwjft/images/raw/master/image/cloud/image-20220216183304542.png)

式中，nft为DFT样本数。如图4(d)-(f)所示，减少DFT训练样本数量后，SL的误差(eE和eF)显著增加，而TL的误差仅略有增加。

仅使用10^2^个DFT样本就可以达到精度，而如果使用SL则需要超过10^3^个DFT样本。

所需DFT样本的减少情况如图5所示。而特定材料的SL需要NSL  = MS × N0样本，而提出的TL只需要NTL = MS +(N0−1)×mt样本，以生成N0组合的NN数据库。计算成本的相应减少率R =  NSL/NTL在很大程度上取决于MS/mt，而N0 >102(通常是这样)。使用MS = 105, mt =  102进行估计(图4)，TL比SL快103倍。

该方法既具有较高的效率，又具有dft级的高精度。最大的错误eF≈101伏/ eE≈100伏,/原子在图4中与违约力收敛公差DFT技术发展水平的代码.



#### CONCLUSION

提出了一种迁移学习方法来训练合金和掺杂的神经网络电位。通过重用现有神经网络中已有的丰富的势能面信息和原子晶格之间的相似性，与传统的能量面方法相比，所提出的能量面方法的速度可以提高几个数量级。

正如这封信中所显示的，先进的机器学习方法在加速基于dft的ab-initio  TCAD方面有很大的潜力。但在这个充满希望的新方向上，还有许多悬而未决的问题。例如，开发自动化误差控制工具，选择合适数量的DFT样本至关重要。本函未提及的其他因素(如温度、压力的变化等)值得进一步研究。此外，值得努力探索其他机器学习方法，如主动学习和/或增强学习。